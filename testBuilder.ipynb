{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasetComposer import DatasetBuilder,compactComposer,test_path,composed_test_path,composed_train_path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raw_data/processed_data/train_pack4.dat'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = json.load(open(test_path,encoding='utf-8'))\n",
    "yyu = compactComposer(tests[:2],\n",
    "                      iterative_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"rank\": [[\"<|f#3|>\", 0], [\"<|f#2|>\", 1], [\"<|f#8|>\", 2], [\"<|f#6|>\", 3], [\"<|f#1|>\", 4], [\"<|f#5|>\", 5], [\"<|f#7|>\", 6], [\"<|f#10|>\", 7], [\"<|f#9|>\", 8], [\"<|f#4|>\", 9]], \"annotate_code\": [\"F3\", \"F2\", \"F8-V3\", \"F6-V1\", \"F1\", \"F5-V2\", \"F7-V1\", \"F10-V0\", \"F9-V1\", \"F4-V4\"], \"explainable_df\": \"{\\\\\"Values\\\\\":{\\\\\"2\\\\\":0.111584309,\\\\\"1\\\\\":-0.0981037975,\\\\\"7\\\\\":0.0950381532,\\\\\"5\\\\\":-0.0291176955,\\\\\"0\\\\\":-0.0138226057,\\\\\"4\\\\\":0.0108692384,\\\\\"6\\\\\":0.0093254151,\\\\\"9\\\\\":0.0082697522,\\\\\"8\\\\\":0.0068284379,\\\\\"3\\\\\":0.0038519981},\\\\\"Variable\\\\\":{\\\\\"2\\\\\":\\\\\"Weight_in_gms\\\\\",\\\\\"1\\\\\":\\\\\"Discount_offered\\\\\",\\\\\"7\\\\\":\\\\\"Prior_purchases\\\\\",\\\\\"5\\\\\":\\\\\"Customer_care_calls\\\\\",\\\\\"0\\\\\":\\\\\"Cost_of_the_Product\\\\\",\\\\\"4\\\\\":\\\\\"Mode_of_Shipment\\\\\",\\\\\"6\\\\\":\\\\\"Customer_rating\\\\\",\\\\\"9\\\\\":\\\\\"Gender\\\\\",\\\\\"8\\\\\":\\\\\"Product_importance\\\\\",\\\\\"3\\\\\":\\\\\"Warehouse_block\\\\\"},\\\\\"effect_abs\\\\\":{\\\\\"2\\\\\":0.111584309,\\\\\"1\\\\\":0.0981037975,\\\\\"7\\\\\":0.0950381532,\\\\\"5\\\\\":0.0291176955,\\\\\"0\\\\\":0.0138226057,\\\\\"4\\\\\":0.0108692384,\\\\\"6\\\\\":0.0093254151,\\\\\"9\\\\\":0.0082697522,\\\\\"8\\\\\":0.0068284379,\\\\\"3\\\\\":0.0038519981},\\\\\"placeholder\\\\\":{\\\\\"2\\\\\":\\\\\"<|f#3|>\\\\\",\\\\\"1\\\\\":\\\\\"<|f#2|>\\\\\",\\\\\"7\\\\\":\\\\\"<|f#8|>\\\\\",\\\\\"5\\\\\":\\\\\"<|f#6|>\\\\\",\\\\\"0\\\\\":\\\\\"<|f#1|>\\\\\",\\\\\"4\\\\\":\\\\\"<|f#5|>\\\\\",\\\\\"6\\\\\":\\\\\"<|f#7|>\\\\\",\\\\\"9\\\\\":\\\\\"<|f#10|>\\\\\",\\\\\"8\\\\\":\\\\\"<|f#9|>\\\\\",\\\\\"3\\\\\":\\\\\"<|f#4|>\\\\\"},\\\\\"annotate_placeholder\\\\\":{\\\\\"2\\\\\":\\\\\"F3\\\\\",\\\\\"1\\\\\":\\\\\"F2\\\\\",\\\\\"7\\\\\":\\\\\"F8-V3\\\\\",\\\\\"5\\\\\":\\\\\"F6-V1\\\\\",\\\\\"0\\\\\":\\\\\"F1\\\\\",\\\\\"4\\\\\":\\\\\"F5-V2\\\\\",\\\\\"6\\\\\":\\\\\"F7-V1\\\\\",\\\\\"9\\\\\":\\\\\"F10-V0\\\\\",\\\\\"8\\\\\":\\\\\"F9-V1\\\\\",\\\\\"3\\\\\":\\\\\"F4-V4\\\\\"},\\\\\"local_rank\\\\\":{\\\\\"2\\\\\":0,\\\\\"1\\\\\":1,\\\\\"7\\\\\":2,\\\\\"5\\\\\":3,\\\\\"0\\\\\":4,\\\\\"4\\\\\":5,\\\\\"6\\\\\":6,\\\\\"9\\\\\":7,\\\\\"8\\\\\":8,\\\\\"3\\\\\":9},\\\\\"local_normalize_scores\\\\\":{\\\\\"2\\\\\":1.0,\\\\\"1\\\\\":-0.89,\\\\\"7\\\\\":0.86,\\\\\"5\\\\\":-0.31,\\\\\"0\\\\\":-0.18,\\\\\"4\\\\\":0.16,\\\\\"6\\\\\":0.15,\\\\\"9\\\\\":0.14,\\\\\"8\\\\\":0.12,\\\\\"3\\\\\":0.1},\\\\\"Sign\\\\\":{\\\\\"2\\\\\":\\\\\"green\\\\\",\\\\\"1\\\\\":\\\\\"red\\\\\",\\\\\"7\\\\\":\\\\\"green\\\\\",\\\\\"5\\\\\":\\\\\"red\\\\\",\\\\\"0\\\\\":\\\\\"red\\\\\",\\\\\"4\\\\\":\\\\\"green\\\\\",\\\\\"6\\\\\":\\\\\"green\\\\\",\\\\\"9\\\\\":\\\\\"green\\\\\",\\\\\"8\\\\\":\\\\\"green\\\\\",\\\\\"3\\\\\":\\\\\"green\\\\\"},\\\\\"local_impact\\\\\":{\\\\\"2\\\\\":1,\\\\\"1\\\\\":2,\\\\\"7\\\\\":1,\\\\\"5\\\\\":2,\\\\\"0\\\\\":2,\\\\\"4\\\\\":1,\\\\\"6\\\\\":1,\\\\\"9\\\\\":1,\\\\\"8\\\\\":1,\\\\\"3\\\\\":1},\\\\\"annotate_placeholder_display\\\\\":{\\\\\"2\\\\\":\\\\\"F3\\\\\",\\\\\"1\\\\\":\\\\\"F2\\\\\",\\\\\"7\\\\\":\\\\\"F8-V3\\\\\",\\\\\"5\\\\\":\\\\\"F6-V1\\\\\",\\\\\"0\\\\\":\\\\\"F1\\\\\",\\\\\"4\\\\\":\\\\\"F5-V2\\\\\",\\\\\"6\\\\\":\\\\\"F7-V1\\\\\",\\\\\"9\\\\\":\\\\\"F10-V0\\\\\",\\\\\"8\\\\\":\\\\\"F9-V1\\\\\",\\\\\"3\\\\\":\\\\\"F4-V4\\\\\"},\\\\\"annotate_placeholder_code\\\\\":{\\\\\"2\\\\\":\\\\\"F3\\\\\",\\\\\"1\\\\\":\\\\\"F2\\\\\",\\\\\"7\\\\\":\\\\\"F8-V3\\\\\",\\\\\"5\\\\\":\\\\\"F6-V1\\\\\",\\\\\"0\\\\\":\\\\\"F1\\\\\",\\\\\"4\\\\\":\\\\\"F5-V2\\\\\",\\\\\"6\\\\\":\\\\\"F7-V1\\\\\",\\\\\"9\\\\\":\\\\\"F10-V0\\\\\",\\\\\"8\\\\\":\\\\\"F9-V1\\\\\",\\\\\"3\\\\\":\\\\\"F4-V4\\\\\"},\\\\\"ftype\\\\\":{\\\\\"2\\\\\":\\\\\"numeric\\\\\",\\\\\"1\\\\\":\\\\\"numeric\\\\\",\\\\\"7\\\\\":\\\\\"categorical\\\\\",\\\\\"5\\\\\":\\\\\"categorical\\\\\",\\\\\"0\\\\\":\\\\\"numeric\\\\\",\\\\\"4\\\\\":\\\\\"categorical\\\\\",\\\\\"6\\\\\":\\\\\"categorical\\\\\",\\\\\"9\\\\\":\\\\\"categorical\\\\\",\\\\\"8\\\\\":\\\\\"categorical\\\\\",\\\\\"3\\\\\":\\\\\"categorical\\\\\"}}\", \"feature_type\": [\"numeric\", \"numeric\", \"categorical\", \"categorical\", \"numeric\", \"categorical\", \"categorical\", \"categorical\", \"categorical\", \"categorical\"], \"contradict\": [\"<|f#2|>\", \"<|f#6|>\", \"<|f#1|>\"], \"support\": [\"<|f#3|>\", \"<|f#8|>\", \"<|f#5|>\", \"<|f#7|>\", \"<|f#10|>\", \"<|f#9|>\", \"<|f#4|>\"], \"ignore\": []}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests[0]['feature_division']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prediction: predictionlabel && predictionlabel: 98.44% && predictionrankB: 1.56% <|section-sep|> featAP featCP featDN featEP featFP featGP featHN featIN featJN featKP featLN featMP <|section-sep|> <mentions> <|section-sep|> featHN:- featIN:- featJN:- featLN:- <|section-sep|> </mentions> <|section-sep|> <explain>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyu[1][1][ 'new_preamble_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dataset.tokenizer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dataset = DatasetBuilder('facebook/bart-base', composed_train_path, composed_test_path,\n",
    "                             iterative_mode=True, composed_already=True, preamble_choice=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prediction: predictionlabel && predictionlabel: 69.02% && predictionrankB: 30.98% <|section-sep|> featAP featCN featDP featEN featFN featGP featHP featIP featJP featKP <|section-sep|> <mentions> featAP featDP featGP featHP featIP featJP featKP <|section-sep|> featCN featEN featFN <|section-sep|> </mentions> <|section-sep|> <explain>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dataset.test_data_raw[0]['new_preamble_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dataset.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp_dataset.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features(input_ids=tensor([37466, 26579,    35, 16782, 33480,  1437, 49145, 16782, 33480,    35,\n",
       "         5913,     4,  4197,   207,  1437, 49145, 16782, 40081,   387,    35,\n",
       "          389,     4,  5208,   207,  1437, 50279, 11930,   591, 11930, 29990,\n",
       "        11930,  5174, 11930,  2796, 11930, 38350, 11930, 12694, 11930,  7331,\n",
       "        11930,  3808, 11930, 12887, 11930,   530,   510,  1437, 50279,  1437,\n",
       "        50277, 11930,   591, 11930,  5174,  1437, 50279, 11930, 29990,  1437,\n",
       "        50279,  1437, 50278,  1437, 50279,  1437, 50270,  1437, 50295,    20,\n",
       "         1380, 24072,    16,  5913,     4,  4197,   135,  1402,    14,     5,\n",
       "          576,   403,    16,   223,     5,  1380,  6929, 16782, 33480,     6,\n",
       "        28695,    14,     5, 11801,     9, 16782, 40081,   387,    16,   129,\n",
       "          389,     4,  5208,   135,     4,  1437, 50292]), attention_mask=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), labels=tensor([    0, 43932,  3744,     7,  1346,     5,  5883,     9,   349,  8135,\n",
       "         1905,  1487,    14,    35, 11930,   591,     6, 11930, 29990,     6,\n",
       "            8, 11930,  5174,    32,     5,   144,  9283,  1575,    77, 36457,\n",
       "           10,  6929,     7,     5,   576,   403,     4,  1437, 50293,     2]), decoder_attention_mask=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dataset.transform(yyu[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features(input_ids=tensor([37466, 26579,    35, 16782, 33480,  1437, 49145, 16782, 33480,    35,\n",
       "         4034,     4,  3103,   207,  1437, 49145, 16782, 40081,   387,    35,\n",
       "          971,     4,  2983,   207,  1437, 49145, 16782, 40081,   347,    35,\n",
       "          706,     4,  3367,   207,  1437, 50275, 11930,   591, 11930,  7496,\n",
       "        11930, 40795, 11930,  2796, 11930,  9763, 11930, 17567, 11930,   725,\n",
       "          487, 11930,  3808, 11930, 39131, 11930, 21738,  1437, 50275,  1437,\n",
       "        50274,  1437, 50270,  1437, 50272,  1437, 50275,  1437, 50268,  1437,\n",
       "        50271,  1437, 50275,  1437, 50269,  1437, 50273,  1437, 50275,  1437,\n",
       "        50267,  1437, 50290]), attention_mask=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), labels=tensor([    0,   133, 17194,  7460,     7,  3008,     5, 20257, 17876,  1380,\n",
       "        16782, 33480,    19,    10, 11801,     9,   198,  4034,     4,  3103,\n",
       "          135,     6,  1380, 16782, 40081,   387,    19,    10, 11801,     9,\n",
       "         2219,   971,     4,  2983,   135,     6,     8,  1380, 16782, 40081,\n",
       "          347,    19,    10, 11801,     9,   198,   706,     4,  3367,   135,\n",
       "            4,  9068,     6,     5,   507, 16782,   568,    16,    14, 16782,\n",
       "        33480,    16,     5,   144, 15186,  6929,     4,  1437, 50288,     2]), decoder_attention_mask=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dataset.train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' predictionlabel': ' C1', 'predictionrankB': ' C2', 'predictionrankC': ' C4', 'predictionrankD': ' C3'}\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open('datasets/simulated_predictions_7l.json'))\n",
    "yyu = compactComposer(data[-1],iterative_mode=False,force_consistency=True)[0]\n",
    "print( {p:' '+l for l,p in yyu[0]['label_placeholders'].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(yyu[0]['reverse_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prediction: predictionlabel && predictionlabel: 47.55% && predictionrankB: 27.13% && predictionrankC: 22.35% && predictionrankD: 2.97% <|section-sep|> featAP featCP featDN featEP featFP featGP featHN featIN featJN featKN featLP featMP featQP featRN featSP featTP featUP featVP featWP featXN featYN featZN featBCN featBDO featBEO featBFO <|section-sep|> <mentions> featAP:+ featCP:+ featEP:+ featFP:+ featGP:+ featLP:+ featMP:+ featQP:+ featSP:+ featTP:+ featUP:+ featVP:+ featWP:+ <|section-sep|> featDN:- featHN:- featIN:- featJN:- featKN:- featRN:- featXN:- featYN:- featZN:- featBCN:- <|section-sep|> featBDO:@ featBEO:@ featBFO:@ </mentions> <|section-sep|> <explain>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyu[0]['new_preamble_3']\n",
    "#\"prediction_confidence_level\": \"C1:5.55%, C2:3.4%, C3:86.31%, C4:4.75%\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The most appropriate label for the test case under consideration with a relatively high confidence level is C3 and this is primarily because the predicted likelihood of the alternative labels, C2, C1, and C4 are 3.4%, 5.55%, and 4.75%, respectively. The label assignment for the case under consideration here  is largely based on the values of F18, F27, F13, F31, and F7, whereas the values of F17, F35, F8, and F10 are not taken into consideration since their attributions indicates that they have insignificant influence on the classifier. Strongly increasing the probability that C3 is actually the true label are the positive variables F18, F27, F13, F7,  and F2. On the contrary, the negative variables driving the classification decision towards the alternative labels are mainly F31, F16, F29, F5, F22, and F26. The other positively supporting variables further increasing the certainty in the classification decision are F3, F28, F11, F34 and F24. With most of the top variables having positive impact on the classifier, it explains why the clasisfier is certain that none of the alternative labels is the true label for the case under consideration.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"F17\",\n",
    "                \"F35\",\n",
    "                \"F8\",\n",
    "                \"F10\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4aea246828f75a58a93204fce55d322b87a38415c2742fb8a88040418150f4d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('annotation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
